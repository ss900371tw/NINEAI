# app_transparency.py
import os
import re
import tempfile
import streamlit as st
import fitz  # PyMuPDF
from dotenv import load_dotenv
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from difflib import SequenceMatcher
from PIL import Image
import ollama  # âœ… æ”¹ç‚ºä½¿ç”¨ Ollama
import google.generativeai as genai
from dotenv import load_dotenv
import os

# ---------- åˆå§‹åŒ– ----------
# âœ… åˆå§‹åŒ– Gemini
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
genai.configure(api_key=GOOGLE_API_KEY)

# ä½¿ç”¨ Gemini 2.5 Pro æ¨¡å‹
model = genai.GenerativeModel("gemini-2.5-pro")
chat = model.start_chat()


# FAISS å‘é‡åº«åˆå§‹åŒ–ï¼ˆè«‹ç¢ºä¿ INDEX_FILE_PATH èˆ‡ embeddings è¨­å®šæ­£ç¢ºï¼‰
INDEX_FILE_PATH = "faiss_index"
vector_store = None
try:
    vector_store = FAISS.load_local(INDEX_FILE_PATH, embeddings=HuggingFaceEmbeddings(), allow_dangerous_deserialization=True)
except Exception as e:
    vector_store = None
    print("âš ï¸ ç„¡æ³•è¼‰å…¥ FAISS å‘é‡åº«ï¼š", e)

# ---------- ä¹å¤§é€æ˜æ€§åŸå‰‡å®šç¾© ----------
TRANSPARENCY_PRINCIPLES = [
    "ä»‹å…¥è©³æƒ…åŠè¼¸å‡ºï¼šæ¸…æ¥šèªªæ˜AIä»‹å…¥çš„å…·é«”å…§å®¹åŠå…¶è¼¸å‡ºçµæœã€‚",
    "ä»‹å…¥ç›®çš„ï¼šæ˜ç¢ºä»‹å…¥çš„ç›®çš„åŠå…¶é æœŸæ•ˆæœã€‚",
    "ä»‹å…¥çš„è­¦å‘Šç¯„åœå¤–ä½¿ç”¨ï¼šèªªæ˜ä»‹å…¥åœ¨ä½•ç¨®æƒ…æ³ä¸‹å¯èƒ½ä¸é©ç”¨ã€‚",
    "ä»‹å…¥é–‹ç™¼è©³æƒ…åŠè¼¸å…¥ç‰¹å¾µï¼šæä¾›é–‹ç™¼éç¨‹ä¸­çš„è©³ç´°è³‡è¨ŠåŠæ‰€ç”¨çš„æ•¸æ“šç‰¹å¾µã€‚",
    "ç¢ºä¿ä»‹å…¥é–‹ç™¼å…¬å¹³æ€§çš„éç¨‹ï¼šç¢ºä¿é–‹ç™¼éç¨‹ä¸­å…¬å¹³æ€§å¾—åˆ°ä¿éšœã€‚",
    "å¤–éƒ¨é©—è­‰éç¨‹ï¼šé€²è¡Œå¤–éƒ¨é©—è­‰ä»¥ç¢ºä¿ä»‹å…¥çš„æœ‰æ•ˆæ€§ã€‚",
    "æ¨¡å‹è¡¨ç¾çš„é‡åŒ–æŒ‡æ¨™ï¼šæä¾›é‡åŒ–çš„æŒ‡æ¨™ä¾†è©•ä¼°æ¨¡å‹çš„è¡¨ç¾ã€‚",
    "ä»‹å…¥å¯¦æ–½å’Œä½¿ç”¨çš„æŒçºŒç¶­è­·ï¼šç¢ºä¿ä»‹å…¥åœ¨å¯¦æ–½å¾ŒæŒçºŒå¾—åˆ°ç¶­è­·ã€‚",
    "æ›´æ–°å’ŒæŒçºŒé©—è­‰æˆ–å…¬å¹³æ€§è©•ä¼°è¨ˆåŠƒï¼šå®šæœŸæ›´æ–°å’Œè©•ä¼°ä»‹å…¥çš„å…¬å¹³æ€§ã€‚"
]

# ---------- è¼”åŠ©å‡½å¼ ----------
def extract_text_by_line(pdf_bytes):
    """ä½¿ç”¨ PyMuPDF æŒ‰ block å–å‡ºæ–‡å­—"""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    lines = []
    for page in doc:
        blocks = page.get_text("blocks")
        for b in blocks:
            text = b[4].strip()
            if text:
                lines.append(text)
    return "\n\n".join(lines)

def get_gemini_response(prompt):
    """ä½¿ç”¨ Gemini æ¨¡å‹å›æ‡‰"""
    try:
        response = chat.send_message(prompt)
        return response.text.strip()
    except Exception as e:
        return f"âš ï¸ Gemini å‘¼å«éŒ¯èª¤ï¼š{e}"
        
        
def build_transparency_prompts(principles, full_text, rag_docs_k=3):
    """
    ç‚ºæ¯ä¸€åŸå‰‡å»ºç«‹ promptã€‚
    """
    prompts = []
    rag_context = ""
    if vector_store:
        merged_query = " ".join(principles[:3])
        try:
            docs = vector_store.similarity_search(merged_query, k=rag_docs_k)
            rag_context = "\n---\n".join(doc.page_content for doc in docs)
        except Exception:
            rag_context = ""

    for p in principles:
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä½¿ç”¨ç¹é«”ä¸­æ–‡çš„å¯©æŸ¥å“¡ï¼Œè«‹æ ¹æ“šä¸‹æ–¹ã€Œç”³è«‹æ–‡ä»¶å…§å®¹ã€åˆ¤æ–·ï¼š
1.æ˜¯å¦æ˜ç¢ºæ¶µè“‹ä¸‹åˆ—é€æ˜æ€§åŸå‰‡
2.æ’°å¯«æ–‡ä»¶ä¸­æ¨¡å‹æ‰€æ¶‰åŠä¸‹åˆ—é€æ˜æ€§åŸå‰‡çš„å…§å®¹ï¼ˆåªå°±æ–‡ä»¶ä¸­æ˜è¼‰å…§å®¹åˆ¤æ–·ï¼Œä¸å¾—æ¨è«–æˆ–è£œè¶³ï¼‰ã€‚

---- è¦æª¢æ ¸çš„åŸå‰‡ ----
{p}
---- æ–‡ä»¶å…§å®¹ï¼ˆç¯€éŒ„ï¼‰ ----
{full_text}
---- å‘é‡æª¢ç´¢åˆ°çš„ç›¸é—œåƒè€ƒæ®µè½ï¼ˆè‹¥æœ‰ï¼‰ ----
{rag_context}
---- å›è¦†æ ¼å¼ï¼ˆè«‹**åš´æ ¼**éµå®ˆï¼Œä»¥åˆ©ç¨‹å¼è§£æï¼‰----
ç‹€æ…‹: å­˜åœ¨ / ä¸å­˜åœ¨
æ‘˜è¦: ï¼ˆä¸€è‡³å…©è¡Œï¼Œèªªæ˜æ–‡ä»¶ä¸­å“ªæ®µæˆ–å¦‚ä½•æåŠã€‚è‹¥ä¸å­˜åœ¨ï¼Œè«‹å¯«ã€Œæœªç™¼ç¾ç›¸é—œæè¿°ã€ã€‚ï¼‰
---- çµæŸ ----
"""
        prompts.append(prompt.strip())
    return prompts

def parse_transparency_response(response_text):
    """è§£æ Ollama å›æ‡‰ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    response_text = response_text.strip()
    original = response_text
    status = "ç„¡æ³•åˆ¤è®€"
    summary = "æœªç™¼ç¾ç›¸é—œæè¿°"

    m = re.search(r"ç‹€æ…‹\s*[:ï¼š]\s*(å­˜åœ¨|ä¸å­˜åœ¨)", response_text)
    if m:
        status = m.group(1).strip()
    else:
        if "å­˜åœ¨" in response_text and "ä¸å­˜åœ¨" not in response_text:
            status = "å­˜åœ¨"
        elif "ä¸å­˜åœ¨" in response_text:
            status = "ä¸å­˜åœ¨"

    m2 = re.search(r"æ‘˜è¦\s*[:ï¼š]\s*(.+?)(?:\n|$)", response_text, flags=re.DOTALL)
    if m2:
        summary = m2.group(1).strip()
    else:
        summary = original[:300].replace("\n", " ").strip()

    return {"ç‹€æ…‹": status, "æ‘˜è¦": summary}

# ---------- ä¸»æµç¨‹èˆ‡ UI ----------
def main():
    st.set_page_config("ğŸ“„ AI ä»‹å…¥é€æ˜æ€§æª¢æ ¸", layout="wide")
    st.title("ğŸ“„ å–®ä¸€ PDF â€” ä¹å¤§é€æ˜æ€§åŸå‰‡è‡ªå‹•æª¢æ ¸ (Ollama)")
    st.markdown("ä¸Šå‚³å–®ä¸€ PDFï¼Œç³»çµ±æœƒé€æ¢æª¢æŸ¥ä¹å¤§é€æ˜æ€§åŸå‰‡æ˜¯å¦åœ¨æ–‡ä»¶ä¸­æ˜è¼‰ï¼Œä¸¦ç”¢ç”Ÿå¯ä¸‹è¼‰çš„ CSV æª”ã€‚")

    uploaded_pdf = st.file_uploader("ğŸ“¥ ä¸Šå‚³ PDF æ–‡ä»¶ï¼ˆå–®ä¸€æª”æ¡ˆï¼‰", type=["pdf"], accept_multiple_files=False)
    use_rag = st.checkbox("ğŸ” å•Ÿç”¨å‘é‡åº«ï¼ˆè‹¥å·²è¼‰å…¥ FAISSï¼Œå¯ä½¿ç”¨ RAG ä¸Šä¸‹æ–‡ï¼‰", value=True)
    analyze_btn = st.button("ğŸš€ é–‹å§‹æª¢æ ¸")

    if uploaded_pdf and analyze_btn:
        pdf_bytes = uploaded_pdf.read()
        pdf_filename = uploaded_pdf.name.rsplit(".", 1)[0]

        with st.spinner("â³ è®€å– PDF ä¸¦åˆ†æä¸­ï¼Œè«‹ç¨å€™..."):
            full_text = extract_text_by_line(pdf_bytes)
            prompts = build_transparency_prompts(
                TRANSPARENCY_PRINCIPLES, full_text,
                rag_docs_k=3 if use_rag and vector_store else 0
            )

            results = []
            for i, p in enumerate(TRANSPARENCY_PRINCIPLES):
                prompt = prompts[i]
                resp = get_gemini_response(prompt)
                parsed = parse_transparency_response(resp)
                results.append({
                    "åŸå‰‡ç·¨è™Ÿ": i+1,
                    "åŸå‰‡åç¨±": p,
                    "ç‹€æ…‹": parsed["ç‹€æ…‹"],
                    "æ‘˜è¦": parsed["æ‘˜è¦"],
                })

        df = pd.DataFrame(results)
        df = df[["åŸå‰‡ç·¨è™Ÿ", "åŸå‰‡åç¨±", "ç‹€æ…‹", "æ‘˜è¦"]]

        st.success("âœ… æª¢æ ¸å®Œæˆ")
        st.markdown(f"æª”æ¡ˆï¼š**{uploaded_pdf.name}**  â†’ å…±æœ‰ {len(df)} é …æª¢æ ¸çµæœ")
        st.dataframe(df, use_container_width=True)

        csv_data = df.to_csv(index=False)
        filename = f"{pdf_filename}_ä¹å¤§é€æ˜æ€§æª¢æ ¸.csv"
        st.download_button(
            label=f"ğŸ“¥ ä¸‹è¼‰ CSVï¼š{filename}",
            data=csv_data,
            file_name=filename,
            mime="text/csv"
        )

        for idx, row in df.iterrows():
            with st.expander(f"ğŸ” ç¬¬ {row['åŸå‰‡ç·¨è™Ÿ']} é …ï¼š{row['åŸå‰‡åç¨±']} â€” ç‹€æ…‹ï¼š{row['ç‹€æ…‹']}"):
                st.markdown(f"**æ‘˜è¦**ï¼š{row['æ‘˜è¦']}")


    elif not uploaded_pdf:
        st.info("è«‹å…ˆä¸Šå‚³ä¸€ä»½ PDFï¼Œç„¶å¾ŒæŒ‰ã€é–‹å§‹æª¢æ ¸ã€‘ã€‚")

if __name__ == "__main__":
    main()
